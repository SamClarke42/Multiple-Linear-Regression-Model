{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 vectors to test the alogirthm with\n",
    "x1 = [1,4,6,5,4,7,8,9,0,5,4,3,2,4,5,-4,-9]\n",
    "x2 = [2,3,6,5,5,7,9,10,0,5,4,2,2,5,7,-3,-10]\n",
    "x3 = [1,3,5,7,2,7,10,4,1,5,5,4,2,3,4,-6,-7]\n",
    "y = [2,4,5,5,4,8,10,8,0,5,3,4,2,5,6,-5,-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(y,*args):\n",
    "    #Multiple linear regression function which takes input of 1 response variable and multiple explanatory variables.\n",
    "    \n",
    "    X = np.array([np.ones(len(y))]).T     # Create vertical vector of 1's.\n",
    "    Y = np.array([y]).T     # Create a vertical vector of the response variable input - y.\n",
    "    \n",
    "    for x in args:\n",
    "        x1 = np.array([x]).T\n",
    "        X = np.concatenate((X,x1),axis=1)      # This loop concantenates the input explanatory vectors to vector X above.\n",
    "    \n",
    "    XX = np.linalg.inv(X.T.dot(X))     # Inverse of the dot product the new vector X with its transpose.\n",
    "    Xy = X.T.dot(Y)     # Dot product the new vector X with the response variable Y\n",
    "    \n",
    "    B = XX.dot(Xy)      # Dot product of the maticies XX and Xy returns the  regression coeffiecnts of the model.\n",
    "    print('Coefficients', B)\n",
    "    \n",
    "    y_hat = X.dot(B)     # Returns the fitted values of the model.\n",
    "    print('Fitted Values', y_hat)\n",
    "    \n",
    "    r = Y - y_hat       # Returns the residuals from the model.\n",
    "    print('Redisuals', r)\n",
    "    \n",
    "    RSS = Y.T.dot(Y) - (B.T.dot(X.T)).dot(Y)\n",
    "    Sr_squared = RSS/(len(Y)-len(args)-1)     # Gives the value of the Residual Standard error squared.\n",
    "    print('Residual Standard error squared', Sr_squared)\n",
    "    \n",
    "    TSS = Y.T.dot(Y)-len(Y)*np.mean(Y)**2\n",
    "    R_squared = 1 - RSS/TSS      # Gives the value of R squared.\n",
    "    print('R Squared' , R_squared)\n",
    "    \n",
    "    adj_R_squared = 1 - (RSS/(len(Y)-len(args)-1))/(TSS/(len(Y)-1))    # Gives the adjusted R squared value.\n",
    "    print('Adjusted R Squared', adj_R_squared)\n",
    "    \n",
    "    varB = Sr_squared*np.linalg.inv(X.T.dot(X))     # Returns the covariance matrix of the model.\n",
    "    print('Covariance matrix', varB)\n",
    "    \n",
    "    t_matrix = np.empty(0)    # Create an empty matrix\n",
    "    \n",
    "    for i in range(len(varB)):\n",
    "        SE = np.sqrt(varB[i][i])    # Loop each value in the diagonal of the covariance matrix.\n",
    "        t = B[i]/SE      # Divide each iteration of the vector B by the value SE.\n",
    "        t_matrix = np.append(t_matrix,t)   # Create a vector with all of these values.\n",
    "    print('t values', t_matrix)   # Returns the t values of the model to see if each variable is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients [[0.15552455]\n",
      " [0.30576907]\n",
      " [0.36761528]\n",
      " [0.34310502]]\n",
      "Fitted Values [[ 1.53962921]\n",
      " [ 3.51076175]\n",
      " [ 5.91135579]\n",
      " [ 5.92418147]\n",
      " [ 3.9028873 ]\n",
      " [ 7.27095018]\n",
      " [ 9.34126489]\n",
      " [ 7.95601912]\n",
      " [ 0.49862957]\n",
      " [ 5.23797143]\n",
      " [ 4.56458707]\n",
      " [ 3.18048241]\n",
      " [ 2.1885033 ]\n",
      " [ 4.24599232]\n",
      " [ 5.63009698]\n",
      " [-4.22902771]\n",
      " [-8.67428508]]\n",
      "Redisuals [[ 0.46037079]\n",
      " [ 0.48923825]\n",
      " [-0.91135579]\n",
      " [-0.92418147]\n",
      " [ 0.0971127 ]\n",
      " [ 0.72904982]\n",
      " [ 0.65873511]\n",
      " [ 0.04398088]\n",
      " [-0.49862957]\n",
      " [-0.23797143]\n",
      " [-1.56458707]\n",
      " [ 0.81951759]\n",
      " [-0.1885033 ]\n",
      " [ 0.75400768]\n",
      " [ 0.36990302]\n",
      " [-0.77097229]\n",
      " [ 0.67428508]]\n",
      "Residual Standard error squared [[0.64057988]]\n",
      "R Squared [[0.97398601]]\n",
      "Adjusted R Squared [[0.96798278]]\n",
      "Covariance matrix [[ 0.0601822   0.00686928 -0.00964566 -0.00368729]\n",
      " [ 0.00686928  0.12092871 -0.08849116 -0.02851899]\n",
      " [-0.00964566 -0.08849116  0.07237681  0.01344534]\n",
      " [-0.00368729 -0.02851899  0.01344534  0.01618868]]\n",
      "t values [0.63396446 0.87928335 1.36645028 2.69662956]\n"
     ]
    }
   ],
   "source": [
    "linear_model(y,x1,x2,x3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
